2024:
@article{XU2024128980,
title = {Tensor robust principal component analysis with total generalized variation for high-dimensional data recovery},
journal = {Applied Mathematics and Computation},
volume = {483},
pages = {128980},
year = {2024},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2024.128980},
url = {https://www.sciencedirect.com/science/article/pii/S0096300324004417},
author = {Zhi Xu and Jing-Hua Yang and Chuan-long Wang and Fusheng Wang and Xi-hong Yan},
keywords = {Tensor robust principal component analysis, Total generalized variation, Tensor singular value decomposition, Tensor nuclear norm, The alternating direction method of multiplier algorithm},
abstract = {In the past few years, tensor robust principal component analysis (TRPCA) which is based on tensor singular value decomposition (t-SVD) has got a lot of attention in recovering low-rank tensor corrupted by sparse noise. However, most TRPCA methods only consider the global structure of the image, ignoring the local details and sharp edge information of the image, resulting in the unsatisfactory restoration results. In this paper, to fully preserve the local details and edge information of the image, we propose a new TRPCA method by introducing a total generalized variation (TGV) regularization. The proposed method can simultaneously explore the global and local prior information of high-dimensional data. Specifically, the tensor nuclear norm (TNN) is employed to develop the global structure feature. Moreover, we introduce the TGV, a higher-order generalization of total variation (TV), to preserve the local details and edges of the underlying image. Subsequently, the alternating direction method of multiplier (ADMM) algorithm is introduced to solve the proposed model. Sufficient experiments on color images and videos have demonstrated that our method is superior to other comparison methods.}
}

@article{10.1145/3698105,
author = {Wang, Qian and Dai, Hong-Ning and Yang, Jinghua and Guo, Cai and Childs, Peter and Kleinsmann, Maaike and Guo, Yike and Wang, Pan},
title = {Learning-based Artificial Intelligence Artwork: Methodology Taxonomy and Quality Evaluation},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3698105},
doi = {10.1145/3698105},
abstract = {With the development of the theory and technology of computer science, machine or computer painting is increasingly being explored in the creation of art. Machine-made works are referred to as artificial intelligence (AI) artworks. Early methods of AI artwork generation have been classified as non-photorealistic rendering, and, latterly, neural style transfer methods have also been investigated. As technology advances, the variety of machine-generated artworks and the methods used to create them have proliferated. However, there is no unified and comprehensive system to classify and evaluate these works. To date, no work has generalized methods of creating AI artwork including learning-based methods for painting or drawing. Moreover, the taxonomy, evaluation, and development of AI artwork methods face many challenges. This article is motivated by these considerations. We first investigate current learning-based methods for making AI artworks and classify the methods according to art styles. Furthermore, we propose a consistent evaluation system for AI artworks and conduct a user study to evaluate the proposed system on different AI artworks. This evaluation system uses six criteria: beauty, color, texture, content detail, line, and style. The user study demonstrates that the six-dimensional evaluation index is effective for different types of AI artworks.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {71},
numpages = {37},
keywords = {AI art, artwork, style transform, painting, methodology taxonomy, quality evaluation}
}

@article{DING2024109170,
title = {Noisy tensor recovery via nonconvex optimization with theoretical recoverability},
journal = {Applied Mathematics Letters},
volume = {157},
pages = {109170},
year = {2024},
issn = {0893-9659},
doi = {https://doi.org/10.1016/j.aml.2024.109170},
url = {https://www.sciencedirect.com/science/article/pii/S0893965924001903},
author = {Meng Ding and Jinghua Yang and Jin-Jin Mei},
keywords = {Noisy tensor recovery, Sparsity, ℓregularization, Theoretical recoverability},
abstract = {Noisy tensor recovery aims to estimate underlying low-rank tensors from the noisy observations. Besides the sparse noise, tensor data can also be corrupted by the small dense noise. Existing methods typically use the Frobenius norm to handle the small dense noise. In this work, we build a new nonconvex model to decompose the low-rank and sparse components. To be specific, we employ the ℓ1 norm to handle the small dense noise term, the ℓ0 ‘norm’ to enforce the sparse outliers, and the tensor nuclear norm to model the underlying low-rank tensor. We develop an effective alternating minimization-based algorithm. Under certain conditions, we prove that the proposed method has a high probability of exactly recovering low-rank and sparse tensors. Numerical experiments showcase the advantage of our method.}
}

@article{10.1145/3674839,
author = {Fu, Lele and Huang, Sheng and Zhang, Lei and Yang, Jinghua and Zheng, Zibin and Zhang, Chuanfu and Chen, Chuan},
title = {Subspace-Contrastive Multi-View Clustering},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {1556-4681},
url = {https://doi.org/10.1145/3674839},
doi = {10.1145/3674839},
abstract = {Most multi-view clustering methods based on shallow models are limited in sound nonlinear information perception capability, or fail to effectively exploit complementary information hidden in different views. To tackle these issues, we propose a novel Subspace-Contrastive Multi-View Clustering (SCMC) approach. Specifically, SCMC utilizes a set of view-specific auto-encoders to map the original multi-view data into compact features capturing its nonlinear structures. Considering the large semantic gap of data from different modalities, we project multiple heterogeneous features into a joint semantic space, namely the embedded compact features are passed through the self-expression layers to learn the subspace representations, respectively. In order to enhance the discriminability and efficiently excavate the complementarity of various subspace representations, we use the contrastive strategy to maximize the similarity between positive pairs while differentiate negative pairs. Thus, the graph regularization is employed to encode the local geometric structure within varying subspaces for optimizing the consistent affinity matrix. Furthermore, to endow the proposed SCMC with the ability of handling the multi-view out-of-samples, we develop a consistent sparse representation (CSR) learning mechanism over the in-samples. To demonstrate the effectiveness of the proposed model, we conduct a large number of comparative experiments on ten challenging datasets, and the experimental results show that SCMC outperforms existing shallow and deep multi-view clustering methods. In addition, the experimental results on out-of-samples illustrate the effectiveness of the proposed CSR.},
journal = {ACM Trans. Knowl. Discov. Data},
month = oct,
articleno = {211},
numpages = {35},
keywords = {Multi-view clustering, subspace clustering, multi-view fusion, contrastive learning}
}

@ARTICLE{10665981,
  author={Liu, Sheng and Zhao, Xi-Le and Leng, Jinsong and Li, Ben-Zheng and Yang, Jing-Hua and Chen, Xinyu},
  journal={IEEE Transactions on Signal Processing}, 
  title={Revisiting High-Order Tensor Singular Value Decomposition From Basic Element Perspective}, 
  year={2024},
  volume={72},
  number={},
  pages={4589-4603},
  keywords={Tensors;Vectors;Convolution;Videos;Data models;Signal processing algorithms;Sensitivity;High-order tensor;low-rank tensor completion;element-based tensor-tensor product;tensor singular value decomposition;exact recovery guarantee},
  doi={10.1109/TSP.2024.3454115}}

@article{10.1145/3656344,
author = {Zhang, Lei and Fu, Lele and Liu, Chen and Yang, Zhao and Yang, Jinghua and Zheng, Zibin and Chen, Chuan},
title = {Toward Few-Label Vertical Federated Learning},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {7},
issn = {1556-4681},
url = {https://doi.org/10.1145/3656344},
doi = {10.1145/3656344},
abstract = {Federated Learning (FL) provides a novel paradigm for privacy-preserving machine learning, enabling multiple clients to collaborate on model training without sharing private data. To handle multi-source heterogeneous data, Vertical Federated Learning (VFL) has been extensively investigated. However, in the context of VFL, the label information tends to be kept in one authoritative client and is very limited. This poses two challenges for model training in the VFL scenario. On the one hand, a small number of labels cannot guarantee to train a well VFL model with informative network parameters, resulting in unclear boundaries for classification decisions. On the other hand, the large amount of unlabeled data is dominant and should not be discounted, and it is worthwhile to focus on how to leverage them to improve representation modeling capabilities. To address the preceding two challenges, we first introduce supervised contrastive loss to enhance the intra-class aggregation and inter-class estrangement, which is to deeply explore label information and improve the effectiveness of downstream classification tasks. Then, for unlabeled data, we introduce a pseudo-label-guided consistency mechanism to induce the classification results coherent across clients, which allows the representations learned by local networks to absorb the knowledge from other clients, and alleviates the disagreement between different clients for classification tasks. We conduct sufficient experiments on four commonly used datasets, and the experimental results demonstrate that our method is superior to the state-of-the-art methods, especially in the low-label rate scenario, and the improvement becomes more significant.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jun,
articleno = {176},
numpages = {21},
keywords = {Vertical federated learning, semi-supervised learning, contrastive learning}
}

@article{XIANG2024120458,
title = {Dual auto-weighted multi-view clustering via autoencoder-like nonnegative matrix factorization},
journal = {Information Sciences},
volume = {667},
pages = {120458},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120458},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524003712},
author = {Si-Jia Xiang and Heng-Chao Li and Jing-Hua Yang and Xin-Ru Feng},
keywords = {Multi-view clustering, Dual auto-weights, Autoencoder-like nonnegative matrix factorization, Adaptive graph learning},
abstract = {Multi-view clustering (MVC) can exploit the complementary information among multi-view data to achieve the satisfactory performance, thus having extensive potentials for practical applications. Although Nonnegative Matrix Factorization (NMF) has emerged as an effective technique for MVC, the existing NMF-based methods still have two main limitations: 1) They solely focus on the reconstruction of original data, which can be regarded as the decoder of an autoencoder, while neglecting the low-dimensional representation learning. 2) They lack the ability to effectively capture both linear and nonlinear structures of data. To solve these problems, in this paper, we propose a Dual Auto-weighted multi-view clustering model based on Autoencoder-like NMF (DA2NMF), which enables a comprehensive exploration of both linear and nonlinear structures. Specifically, we establish an autoencoder-like NMF model that learns linear low-dimensional representations by integrating data reconstruction and representation learning within a unified framework. Moreover, the adaptive graph learning is introduced to explore the nonlinear structures in data. We further design a dual auto-weighted strategy to adaptively compute weights for different views and low-dimensional representations, thereby obtaining an enhanced consistent graph. An effective algorithm based on Multiplicative Update Rule (MUR) is developed to solve the DA2NMF with the theoretical convergence guarantee. Experimental results show that the proposed DA2NMF can effectively improve the clustering performance compared with the state-of-the-art MVC algorithms.}
}

@article{LIAO2024120024,
title = {A neural tensor decomposition model for high-order sparse data recovery},
journal = {Information Sciences},
volume = {658},
pages = {120024},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.120024},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523016092},
author = {Tianchi Liao and Jinghua Yang and Chuan Chen and Zibin Zheng},
keywords = {Tensor completion, Convolutional neural networks, Tensor-ring decomposition, Rank robustness},
abstract = {Tensor decomposition has attracted wide attention in the low-rank tensor completion (LRTC) problem because of its marvelous recovering ability to missing entries. However, previous LRTC methods are generally based on linear and shallow models, which are prone to overfitting when the data is sparse, resulting in significantly degraded performance. Meanwhile, the models are highly sensitive and suffer from the difficult rank selection problem. To address these issues, we propose an effective and novel tensor-ring (TR) decomposition method based on the convolutional computation (ConvTR), which can be regarded as a natural extension of deep learning models for the LRTC problem. Specifically, ConvTR employs a multi-layer convolutional neural network (CNN) to model the complex interactions between TR factors. Each element in the index vector of the observation tensor can be embedded as a corresponding tensor slice in the factor tensor decomposed by the TR model. These individual slice matrices are then concatenated to get a wider matrix used for extracting the nonlinear features by feeding them into a 2D convolutional layer. A fully-connected layer is utilized to aggregate the final convoluted features to a scalar value, which is the desired missing entry indexed by the original index vector exactly. Extensive experiments on various common datasets verified the effectiveness of the proposed method and demonstrated its superior to the traditional TR-based completion methods and other state-of-the-art network-based methods.}
}

@ARTICLE{10409254,
  author={Yang, Jin-Yu and Li, Heng-Chao and Yang, Jing-Hua and Pan, Lei and Du, Qian and Plaza, Antonio},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={Multifrequency Graph Convolutional Network With Cross-Modality Mutual Enhancement for Multisource Remote Sensing Data Classification}, 
  year={2024},
  volume={62},
  number={},
  pages={1-14},
  keywords={Laser radar;Task analysis;Feature extraction;Data models;Logic gates;Convolutional neural networks;Bipartite graph;Bipartite graph (BG);contrastive learning;gated fusion;graph convolutional neural networks (CNNs);multifrequency;multisource remote sensing (RS) data classification},
  doi={10.1109/TGRS.2024.3356510}}
